# Sagemaker-Medical-Domain-Expert-Model

## Project Introduction
Develop a proof of concept (POC) for a domain expert model. This model will be trained on a dataset of domain-specific knowledge (finance, medical, or IT domain knowledge). The model can then be used to create chat applications, internal knowledge applications, or text content generation for company collateral.


## Project Objective
To train (fine-tune) a large language model. This model should become a domain expert, capable of generating informative, accurate, and contextually relevant text responses. Think of it as creating a knowledgeable consultant for the company!


## Overview of Project Tasks
Fine-tuning the Language Model: Utilize Amazon Sagemaker and other AWS tools to fine-tune the Meta Llama 2 7B foundation model. This model has been trained for text-generation tasks. The goal is to adapt this model to your selected domain, enhancing its ability to understand and generate domain-specific text. 
Deliverables
Trained Model: A fine-tuned language model proficient in your chosen domain. 


## Steps Used in the Project:
1- Dataset Selection: A dataset relevant to the Medical domain is selected. The chosen dataset contains unstructured text discussing Genomic profiling for clinical decision making in myeloid neoplasms and acute leukemia.

2- Environment Configuration:

  -An AWS SageMaker IAM Role is configured to provide necessary permissions for accessing AWS resources.
  -An AWS SageMaker Notebook Instance is set up for developing and running code.
  -A GPU instance (ml.g5.2xlarge) is requested for fine-tuning the language model.

3- Fine-tuning the Language Model:

-The Meta Llama 2 7B foundation model is deployed on the AWS platform.
-Python scripts are employed to fine-tune the model on the selected Medical domain dataset, enhancing its understanding of domain-specific language and concepts.

4- Model Deployment:

  -The fine-tuned language model is deployed on SageMaker to make it accessible for inference.
  
5- Testing and Evaluation:

  -The deployed model is tested and evaluated for its responses to domain-specific knowledge and text-generation tasks relevant to the Medical domain. As part of the project evaluation, I conducted a comparative analysis between the fine-tuned model and the deployed model to discern any differences in their performance. This comparative assessment aimed to gauge the effectiveness of fine-tuning the language model on domain-specific data.


## Technologies Used:
1-Amazon SageMaker: The project utilizes Amazon SageMaker, a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning models quickly.

2-Meta Llama 2 7B Model: The Meta Llama 2 7B foundation model serves as the base for fine-tuning. This model has been pre-trained for text-generation tasks and will be adapted to the Medical domain through fine-tuning.

3-Python: Python programming language is extensively used for scripting and interacting with AWS services, including SageMaker.

4-AWS Services: The project leverages various AWS services, including IAM (Identity and Access Management) for managing access to AWS services securely, EC2 (Elastic Compute Cloud) for requesting GPU instances for model training, and S3 (Simple Storage Service) for storing datasets and model artifacts.


## Comparative Analysis:
The project includes a comparative analysis between the fine-tuned and deployed models to assess performance, validating the effectiveness of fine-tuning on domain-specific data.


## Documentation and Submission:
A comprehensive report documenting the results is prepared for submission.
